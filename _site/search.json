[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Este material es parte del curso interno de Introducción a la Revisión Sistemática con Meta-análisis  © 2025 Instituto Nacional de Epidemiología “Dr. Juan H. Jara” (ANLIS) -  CC BY-NC 4.0",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "index.html#introducción",
    "href": "index.html#introducción",
    "title": "",
    "section": "Introducción",
    "text": "Introducción",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "index.html#clasificación-de-los-estudios-de-casos-y-controles",
    "href": "index.html#clasificación-de-los-estudios-de-casos-y-controles",
    "title": "Unidad 4: Estudios de casos y controles",
    "section": "Clasificación de los estudios de casos y controles",
    "text": "Clasificación de los estudios de casos y controles\nEn los últimos tiempos, se ha profundizado en los aspectos metodológicos de los estudios de casos y controles; y también se ha clarificado la estrecha relación que existe con los estudios de cohorte, lo que ha permitido el desarrollo de diferentes variantes. Describiremos brevemente algunas de ellas a continuación:\n\nEstudios caso-cohorte. En esta variante, la definición de casos y controles se encuentra anidada en una cohorte fija, se utiliza un enfoque de incidencia acumulada.\nEstudios de casos y controles anidado o de grupo de riesgo. Es similar al anterior, sólo que se trata de una cohorte dinámica, y un enfoque de densidad de incidencia.\nEstudios caso-autocontrol. Esta variante utiliza al mismo sujeto que se consideró como caso, como su propio control. Este tipo de estrategia se suele utilizar para exposiciones que son de corta duración y que cambian en el tiempo y con eventos que son fáciles de detectar.\nEstudios de mortalidad proporcional. Tanto los casos como los controles se obtienen de los registros de mortalidad poblacionales. Rothman dice que este tipo de controles son aceptables, sólo si la distribución de la exposición entre los grupos es similar a la que presenta la base poblacional.\nEstudios de caso-caso. En esta estrategia se compara la historia de exposición en subgrupos de casos. En el caso de enfermedades infecciosas, es posible conformar diversos subgrupos de enfermedad, partiendo de datos de vigilancia epidemiológica.\n\nQuienes desean profundizar estos tópicos sobre el diseño de los CyC, pueden leer el capítulo correspondiente de “Epidemiología. Diseño y análisis de estudios” de Hernández-Ávila (2011) . Comenzaremos ahora con la parte de análisis de estos diseños.",
    "crumbs": [
      "Unidad 4: Estudios de casos y controles"
    ]
  },
  {
    "objectID": "index.html#análisis-de-estudios-de-casos-y-controles",
    "href": "index.html#análisis-de-estudios-de-casos-y-controles",
    "title": "Unidad 4: Estudios de casos y controles",
    "section": "Análisis de estudios de casos y controles",
    "text": "Análisis de estudios de casos y controles\nEn estudios de CC, la medida de asociación principal es el odds ratio (OR) de la exposición. Este se calcula comparando la frecuencia de exposición entre casos y controles:\n\\[\nOR = \\frac{Odds~exposición~casos}{Odds~exposición~controles}\n\\]\nEl modelo multivariado a utilizar para estudios de casos y controles no apareados es la regresión logística, que desarrollaremos a continuación. Por otro lado, los estudios de CC apareados se analizan mediante modelos de regresión logística condicional, los cuales abordaremos brevemente al final de la unidad.\n\n@escuelanacionaldesanidad\n@field2014\n@ortegacalvo2002\n@rothman2012\n@silvaayçaguer1995\n@thompson1994",
    "crumbs": [
      "Unidad 4: Estudios de casos y controles"
    ]
  },
  {
    "objectID": "index.html#referencias",
    "href": "index.html#referencias",
    "title": "Unidad 4: Estudios de casos y controles",
    "section": "Referencias",
    "text": "Referencias",
    "crumbs": [
      "Unidad 4: Estudios de casos y controles"
    ]
  },
  {
    "objectID": "reg_logistica.html",
    "href": "reg_logistica.html",
    "title": "Regresión logística",
    "section": "",
    "text": "Este material es parte de la Unidad 4 del curso de Epidemiología - Nivel Avanzado  © 2025 Instituto Nacional de Epidemiología “Dr. Juan H. Jara” (ANLIS) -  CC BY-NC 4.0",
    "crumbs": [
      "Regresión logística"
    ]
  },
  {
    "objectID": "reg_logistica.html#introducción",
    "href": "reg_logistica.html#introducción",
    "title": "Regresión logística",
    "section": "Introducción",
    "text": "Introducción\nCuando la variable dependiente es dicotómica o binaria, es decir, tiene dos categorías mutuamente excluyentes (éxito/fracaso; sí/no; positivo/negativo, etc.), los modelos de regresión lineal no son el abordaje más adecuado para el análisis. Consideremos un evento de salud que puede ocurrir o no (variable dependiente). Por ejemplo:\n\nUn paciente hospitalizado muere/no muere antes del alta.\nUn niño nace con/sin una malformación congénita.\nUn sujeto operado se infecta/no se infecta en el postoperatorio.\nUn niño camina/no camina a los 11 meses.\nUna droga mejora/no mejora los síntomas depresivos.\n\nTeniendo en cuenta que nuestra variable respuesta es dicotómica:\n\\[\nY = 1 \\rightarrow Si~el~hecho~ocurre \\\\\nY  = 0 \\rightarrow Si~el~hecho~no~ocurre\n\\]\nSi representáramos los datos con una función lineal, obtendríamos el siguiente gráfico:\n\n\n\n\n\n\n\n\n\nMatemáticamente, la función exponencial representa mejor esta relación:\n\n\n\n\n\n\n\n\n\nLa regresión logística se utiliza en los casos en que la variable dependiente es binaria, mientras que las variables independientes pueden ser de cualquier tipo (categóricas, dicotómicas, numéricas discretas o continuas). En vez de la ecuación de la recta, ahora tenemos otra ecuación que expresa la variable respuesta (\\(Y\\)) en función de la/las variables independientes. Esta ecuación, en realidad, expresa la probabilidad de que ocurra un hecho en función de ciertas variables que se presumen relevantes.\nLa expresión analítica es:\n\\[\nP(Y=1)_x=\\frac{1}{1+e^{(-\\alpha-\\beta_1X_1-\\beta_2X_2-\\dots-\\beta_kX_k)}}\n\\]\nPara comprender lo que significan los coeficientes \\(\\beta\\) del modelo, vamos a hacer algunas operaciones matemáticas. Comenzaremos por realizar una transformación logística, es decir, dividir ambos miembros de la ecuación por \\(1-P_{(Y=1)}\\):\n\\[\n\\frac{P(Y=1)_x}{1-P(Y=1)_x}=\\frac{\\frac{1}{1+e^{(-\\alpha-\\beta_1X_1-\\beta_2X_2-\\dots-\\beta_kX_k)}}}{1-\\frac{1}{1+e^{(-\\alpha-\\beta_1X_1-\\beta_2X_2-\\dots-\\beta_kX_k)}} }\n\\]\nSi ahora aplicamos logaritmo natural (\\(ln\\)) a ambos miembros de la ecuación, y aplicamos propiedades de los logaritmos, nos queda:\n\\[\nln\\bigg[\\frac{P_x}{1-P_x}\\bigg] = \\alpha + \\sum\\beta_ix_i\n\\]\nSi observamos el término que está entre corchetes, recordaremos que el cociente entre la probabilidad que un suceso ocurra, y la probabilidad de que no ocurra, es lo que conocemos como Odds, entonces:\n\\[\nln(Odds) = \\alpha+\\sum\\beta_ix_i\n\\]\nSi despejamos Odds de la ecuación anterior, podemos concluir entonces que:\n\\[\nOdds = e^{(\\alpha+\\sum\\beta_ix_i)}\n\\]\nPara comprender mejor cómo se interpretarán los coeficientes en la regresión logística, supongamos que queremos modelar la probabilidad de que un evento ocurra, \\(P_{(Y=1)}\\), en función de una única variable independiente dicotómica, que toma el valor 0 cuando la condición está ausente (\\(x=0\\)) y el valor 1 cuando está presente (\\(x=1\\)). Entonces:\nPara \\(x=1\\)\n\\[\nOdds_{evento/expuestos}=e^{(\\alpha+\\beta)}\n\\]\nPara \\(x=0\\)\n\\[\nOdds_{evento/expuestos}=e^{(\\alpha)}\n\\]\nEntonces, si queremos calcular el odds-ratio (OR):\n\\[\nOR = \\frac{e^{(\\alpha+\\beta)}}{e^\\alpha}=e^\\beta\n\\]\nPor lo tanto:\n\\[\nln\\; OR = \\beta\n\\]\nDe esta forma, vemos que \\(\\beta\\) = incremento del logaritmo del OR por cada unidad de incremento de \\(x\\).\nExtendiendo el razonamiento para la regresión logística múltiple, es decir cuando modelamos en función de más de una variable independiente, volvemos a la ecuación:\n\\[\nln(Odds) = \\alpha + \\sum\\beta_ix_i\n\\]\nDonde cada \\(\\beta_i\\): Incremento en log-odds para una unidad de incremento en \\(x_i\\) con todas las otras \\(x_i\\) constantes.\nIncluimos esta deducción para facilitar la comprensión del tema, pero para quienes el lenguaje matemático les es adverso, pueden hacer un “acto de fe” y quedarse con las conclusiones.",
    "crumbs": [
      "Regresión logística"
    ]
  },
  {
    "objectID": "reg_logistica.html#modelos-lineales-generalizados",
    "href": "reg_logistica.html#modelos-lineales-generalizados",
    "title": "Regresión logística",
    "section": "Modelos lineales generalizados",
    "text": "Modelos lineales generalizados\nLa regresión logística forma parte de la familia de modelos lineales generalizados (GLM por su nombre en inglés, Generalized Linear Models), utilizados para predecir la probabilidad de que ocurra un evento binario (como infectado/no infectado, enfermo/no enfermo, sobreviviente/fallecido, etc.) en función de una o más variables independientes. Los GLM extienden los modelos de regresión lineales al permitir el uso de distribuciones no normales de errores (como binomiales, Poisson, gamma, entre otras) y varianzas no constantes. Estos modelos se caracterizan por una estructura de errores específica y una función de enlace que conecta la variable respuesta con la(s) variable(s) independiente(s).\nEn el caso de la regresión logística, donde la variable respuesta es binaria (0, 1), la estructura de errores pertenece a la familia de distribución binomial. La función de enlace típica para linealizar la relación entre la variable respuesta y la(s) variable(s) independiente(s) es la función logit, que es el logaritmo natural del odds-ratio (OR). Esta función de enlace transforma la escala de probabilidades (de 0 a 1) a una escala lineal (de \\(-\\infty\\) a \\(+\\infty\\)), lo que facilita la modelización de la relación entre las variables independientes y la variable respuesta binaria.",
    "crumbs": [
      "Regresión logística"
    ]
  },
  {
    "objectID": "reg_logistica.html#componentes-del-modelo-logístico",
    "href": "reg_logistica.html#componentes-del-modelo-logístico",
    "title": "Regresión logística",
    "section": "Componentes del modelo logístico",
    "text": "Componentes del modelo logístico\nAl igual que en la regresión lineal múltiple (RLM), antes de adentrarnos en el modelado, exploraremos cómo interpretar la salida de R para un modelo de regresión logística obtenida a partir de la función summary(modelo):\n\n\n\nCall:\nglm(formula = y ~ x1 + x2, family = binomial, data = datos)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -0.3362     0.2816  -1.194   0.2325    \nx1B           0.4267     0.4012   1.064   0.2875    \nx1C           0.7016     0.3996   1.756   0.0791 .  \nx2            1.2669     0.2103   6.023 1.71e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 277.08  on 199  degrees of freedom\nResidual deviance: 221.48  on 196  degrees of freedom\nAIC: 229.48\n\nNumber of Fisher Scoring iterations: 4\n\n\nLos elementos a tener en cuenta son:\n\nCall: Muestra la fórmula del modelo utilizado.\nEstimate: Contiene los coeficientes \\(\\beta\\) estimados, incluyendo el intercepto (\\(\\beta_0\\)) y las variables explicativas (\\(\\beta_i\\)). Al aplicar a estos coeficientes la función exp(), que representa la función inversa del logaritmo natural, se obtiene el Odds Ratio (OR). Esto implica que los coeficientes de las variables independientes se interpretan como el OR de que ocurra el evento para cada incremento de la variable independiente, manteniendo constantes las demás variables independientes.\nStd. Error: Representa el error estándar asociado a cada coeficiente.\nz value: Corresponde al estadístico del test de Wald para evaluar la significancia de cada coeficiente.\nPr(&gt;|z|): Proporciona los p-valores asociados al test de Wald, que indican si los coeficientes son significativamente diferentes de cero.\n\nAdemás, en la parte final de la salida se presentan:\n\nNull deviance: La devianza del modelo nulo, que asume que ninguna de las variables explicativas tiene efecto.\nResidual deviance: La devianza del modelo ajustado, que indica cuánto se reduce la devianza al incluir las variables explicativas.\nAIC (Criterio de Información de Akaike): Una medida de la calidad del modelo, penalizando por la complejidad para favorecer modelos más parsimoniosos.\nNumber of Fisher Scoring iterations: Número de iteraciones realizadas durante el proceso de estimación de parámetros del modelo.\n\nA continuación, profundizaremos en el significado de algunos de estos conceptos.\n\nTest de Wald\nEl test de Wald se utiliza para evaluar la significación de una variable dentro del modelo. De manera similar al test \\(F\\) parcial en la regresión lineal múltiple, este test contrasta la hipótesis nula:\n\\[\nH_0 : \\beta_i = 0\n\\]\nExpresamos la prueba en términos del coeficiente \\(\\beta_i\\) porque esta formulación es análoga a la utilizada en regresión lineal. Sin embargo, en regresión logística, los resultados suelen presentarse en términos de odds-ratio (OR).\nDado que una pendiente \\(\\beta_i = 0\\) implica un OR de 1, la hipótesis nula también puede expresarse como “la razón de probabilidades es 1”. Esto significa que la variable explicativa no tiene capacidad predictiva, ya que las probabilidades de los grupos comparados son iguales.\nLa interpretación sigue criterios comunes en inferencia estadística: valores de p menores a 0,05 sugieren evidencia suficiente para rechazar la hipótesis nula, indicando que la variable contribuye significativamente al modelo (p &lt; 0,1 podría considerarse en contextos más flexibles). Es fundamental recordar que, en regresión logística, los coeficientes \\(\\beta_i\\) no se interpretan directamente. Para obtener su efecto sobre la razón de probabilidades, se debe calcular su exponencial \\(\\exp(\\beta_i)\\).\n\n\nMáxima verosimilitud\nMientras que en la regresión lineal múltiple (RLM) los coeficientes \\(\\beta\\) se obtenían por el método de los mínimos cuadrados, en la regresión logística (RLOG) se obtienen mediante el método de máxima verosimilitud (ML, por su nombre en inglés, Maximum Likelihood). El fundamento de esta técnica radica en utilizar la información disponible de los datos de la muestra para seleccionar el valor del parámetro que maximiza la probabilidad de observar los resultados muestrales. La ML, entonces, se calcula mediante un proceso iterativo.\nPor lo tanto, una medida adecuada para evaluar la concordancia del modelo con los datos sería el producto de todas las probabilidades (predichas por el modelo), que los \\(n\\) sujetos de la muestra realmente tengan la condición observada. Es decir, un buen modelo sería el que asigne una probabilidad de 1 (\\(p = 1\\)) a cada sujeto que realmente tenga la condición y de 0 (\\(p = 0\\)) a cada sujeto libre de ella, correspondiendo a una ML de 1. Por el contrario, un modelo deficiente tendría una verosimilitud cercana a 0. En consecuencia, la proximidad de la verosimilitud a 1 expresa cuán eficiente ha sido el ajuste realizado para modelar la realidad.\n\n\nDeviance\nLa deviance (\\(D\\)), también conocida como devianza o distancia, se define como:\n\\[\nD = -2lnV\n\\]\nDonde \\(V\\) es la verosimilitud del modelo.\nDado que, como explicamos anteriormente, \\(V &lt; 1\\), su logaritmo siempre será negativo, haciendo que la devianza sea siempre un número positivo. El grado de ajuste de un modelo será mejor cuanto más próxima a 1 es la verosimilitud y, en consecuencia, cuanto más cercana a cero sea la devianza.\nAl ajustar el modelo se calculan dos devianzas: la correspondiente al “modelo nulo” (\\(D_0\\)), que es aquel en que no se ha incorporado ninguna variable independiente, y la \\(D_f\\) del modelo. La diferencia (o cociente) entre estas dos devianzas mide la “contribución” que hacen las variables incorporadas al modelo:\n\\[\n-2lnV_0 - (-2lnV_f)\n\\]\nLa \\(D_0\\) es siempre mayor que la de cualquier modelo ampliado. Esto es razonable, ya que el modelo nulo es mucho menos complejo (no incorpora información de variables “explicativas”) y, por lo tanto, tendrá una capacidad predictiva inferior.\n\n\nLikelihood Ratio Test\nEl Likelihood Ratio Test (LRT) compara la probabilidad de los datos observados bajo dos modelos: uno que incluye los predictores y otro que no. Para ello, evalúa la diferencia en los residuos entre ambos modelos, lo que equivale a comparar sus respectivas devianzas (\\(D\\)).\n\\[\nD_0 - D = -2lnV_0 + 2lnV = -2ln(V_0-V) = -2ln\\bigg(\\frac{V_0}{V}\\bigg)  \\]\nDonde \\(\\frac{V_0}{V}\\) es el Likelihood Ratio o razón de verosimilitud.\nEl LRT permite evaluar la significancia de la incorporación de predictores al modelo, comparándolo con el modelo nulo (sin predictores).El estadístico de prueba sigue una distribución \\(\\chi^2\\) con grados de libertad equivalentes al número de predictores incluidos en el modelo.\nEn términos prácticos, la razón de verosimilitud se obtiene al comparar las devianzas de dos modelos, uno con más y otro con menos predictores. Esto permite determinar si la inclusión de ciertas variables mejora significativamente el ajuste del modelo. En la salida de un modelo, los valores de devianza aparecen bajo los títulos Null deviance (para el modelo nulo) y Residual deviance (para el modelo con predictores).\n\n\nCriterio de Información de Akaike\nEl Criterio de Información de Akaike (AIC) es una medida de la calidad relativa de un modelo estadístico, para un conjunto dado de datos. Se define como:\n\\[\nAIC= 2k – 2ln(D)\n\\]\nDonde,\n\n\\(k\\): número de parámetros del modelo.\n\\(D\\): devianza del modelo.\n\nEl AIC proporciona un método para la selección de modelos, donde valores menores de AIC indican un mejor ajuste del modelo a los datos.\n\n\n\n\n\n\nPara comparar dos o más modelos de regresión logística, se pueden utilizar las siguientes técnicas:\n\nAIC: El primer término de la ecuación del AIC penaliza por la inclusión de variables en el model (\\(2k\\)), mientras que el segundo compensa por la bondad de ajuste (\\(2ln(D)\\)). Por lo tanto, dado un conjunto de modelos para los datos, el modelo preferido es aquel con el valor mínimo de AIC.\nEn R, realizamos la comparación con la función AIC():\n\n# Genero modelo más sencillo\nmod2 &lt;- update(modelo, ~.-x1)\n\n# Comparo AIC\nAIC(modelo, mod2)\n\n       df      AIC\nmodelo  4 229.4788\nmod2    2 228.6598\n\n\nLikelihood Ratio Test: Este test permite comparar dos modelos evaluando la significancia de la diferencia de devianzas. El estadístico tiene una distribución \\(\\chi^2\\) con grados de libertad iguales a la diferencia en el número de parámetros entre los dos modelos comparados.\nLa función anova() del paquete stats permite comparar modelos por si diferencia de varianzas:\n\nanova(modelo, mod2, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: y ~ x1 + x2\nModel 2: y ~ x2\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1       196     221.48                     \n2       198     224.66 -2  -3.1811   0.2038\n\n\nTambién podemos usar la función test_lrt() del paquete performance:\n\ntest_lrt(modelo, mod2)\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   | Model | df | df_diff | Chi2 |     p\n--------------------------------------------\nmodelo |   glm |  4 |         |      |      \nmod2   |   glm |  2 |      -2 | 3.18 | 0.204\n\n\n\n\n\n\n\n\nBondad de ajuste\nDe forma análoga al Coeficiente de Determinación (\\(R^2\\)) utilizado en regresión Lineal, se han desarrollado diversos coeficientes para estimar la proporción de variabilidad explicada por las variables independientes en modelos de regresión logística.\nEn R, podemos calcular estos coeficientes utilizando el paquete performance:\n\nCoeficiente de McFadden: Es una de las medidas más utilizadas y se interpreta de manera similar al \\(R^2\\) en regresión lineal:\n\nr2_mcfadden(modelo)\n\n# R2 for Generalized Linear Regression\n       R2: 0.201\n  adj. R2: 0.193\n\n\nCoeficiente de Cox y Snell: Se basa en la razón de verosimilitud y es una generalización del \\(R^2\\) en modelos lineales:\n\nr2_coxsnell(modelo)\n\nCox & Snell's R2 \n       0.2427035 \n\n\nCoeficiente de Nagelkerke: El coeficiente de Nagelkerke es una versión corregida del coeficiente de Cox y Snell, cuyo valor máximo es menor a 1 incluso para un modelo perfecto, corrigiendo así la tendencia de subestimación del coeficiente \\(R^2\\).\n\nr2_nagelkerke(modelo)\n\nNagelkerke's R2 \n      0.3237019 \n\n\nCoeficiente de Tjur: Calcula el Coeficiente de Discriminación (\\(D\\)) para modelos lineales generalizados con variable respuesta binaria. Es el proporcionado por defecto para modelos de regresión logística en performance:\n\nr2(modelo)\n\n# R2 for Logistic Regression\n  Tjur's R2: 0.251\n\n\nTest de Hosmer-Lemeshow: Ninguno de los coeficientes anteriores mide directamente la calidad del ajuste del modelo. Para evaluar esto, utilizamos el test de Hosmer-Lemeshow, que compara las probabilidades predichas con las observadas.\nEste test calcula un estadístico de distribución \\(\\chi^2\\) con \\(n-2\\) grados de libertad, utilizando varios grupos basados en los deciles de las probabilidades predichas. En R:\n\nperformance_hosmer(modelo)\n\n# Hosmer-Lemeshow Goodness-of-Fit Test\n\n  Chi-squared: 12.091\n           df:  8    \n      p-value:  0.147\n\n\nEn un test de bondad de ajuste, la hipótesis nula siempre afirma que el modelo propuesto se ajusta bien a los datos observados. Por lo tanto, un p-valor superior a 0.05 implica que lo observado se ajusta suficientemente bien a lo esperado bajo el modelo.\n\n\n\nCapacidad predictiva del modelo\nOtro aspecto a evaluar en un modelo de RLOG es su capacidad de discriminación, es decir, la habilidad del modelo para distinguir entre individuos en los que ocurre el evento y aquellos en los que no. Una medida común de esta discriminación es el área bajo la curva ROC (Receiver Operating Characteristic), que se construye utilizando las probabilidades predichas por el modelo.\nPara evaluar la efectividad del modelo en la clasificación de observaciones, se puede construir una tabla de clasificación que cruza el verdadero valor de la observación (1 o 0) con la predicción del modelo. Como el modelo de RLOG estimará probabilidades en el rango de 0 a 1, tendremos que elegir un punto de corte en forma arbitraria. Por ejemplo, podríamos decidir que probabilidades estimadas mayores a 0.5 sean indicativas de que el evento ha ocurrido, mientras que probabilidades menores o iguales a 0.5 indiquen que el evento no ha ocurrido.\nLa capacidad predictiva de un modelo de regresión logística se resume utilizando los conceptos de sensibilidad y especificidad. Quienes trabajen en áreas relacionadas al diagnóstico estarán más familiarizados con estos conceptos.\n\nSensibilidad: Probabilidad de que el modelo prediga correctamente que el evento ha ocurrido cuando realmente ha ocurrido.\n\\[\nP(\\hat{y} = 1|y = 1)\n\\]\nEspecificidad: Probabilidad de que el modelo prediga correctamente que el evento no ha ocurrido cuando realmente no ha ocurrido.\n\n\\[\nP(\\hat{y}=0|y=0)\n\\]\nLa curva ROC es un gráfico que representa la sensibilidad en función de 1 menos la especificidad. Si vamos modificando los valores del valor de corte y representamos la sensibilidad (en el eje Y) frente a 1 – especificidad (en el eje X) tenemos la curva ROC. Cuanto mayor sea el área bajo esta curva, mejores serán las predicciones del modelo.\n\n\n\n\n\n\n\n\n\nEsta curva representa, para todos los pares posibles de individuos formados por uno en el que ocurrió el evento y otro en el que no, la proporción de aquellos para los cuales el modelo predice una mayor probabilidad de haber experimentado el evento.\n\n\n\n\n\n\nPara evaluar un modelo de RLOG deberíamos observar:\n\nCoeficientes de determinación : Variabilidad explicada por el modelo.\nTest de Hosmer‐Lemeshow: Bondad de ajuste, diferencia entre los valores predichos por el modelo y los valores observados en la muestra.\nAIC, LRT o ANOVA: Comparación de modelos.\nCurva ROC: Capacidad predictiva (especialmente cuando el propósito es predictivo).\nIntervalos de confianza: Exactitud del coeficiente.",
    "crumbs": [
      "Regresión logística"
    ]
  },
  {
    "objectID": "reg_logistica.html#construcción-del-modelo-en-r",
    "href": "reg_logistica.html#construcción-del-modelo-en-r",
    "title": "Regresión logística",
    "section": "Construcción del modelo en R",
    "text": "Construcción del modelo en R\nEl ajuste de un modelo de regresión logística en R se realiza utilizando la función glm(), del paquete stats:\n\nglm(formula, family = binomial(link = \"logit\"), data)\n\n\nFormula: Especifica la relación entre la variable dependiente y las variables independientes en el modelo. Sigue la estructura estándar:\n\n\\[\nvariable\\_dependiente \\sim variable\\_indep_1 + variable\\_indep_2 +\\dots+ variable\\_indep_n\n\\]\n\nFamily: Se refiere a la familia de distribuciones y la función de enlace utilizada para ajustar el modelo. Las opciones comunes incluyen:\n\ngaussian(): Utilizada para variables dependientes continuas con distribución normal. El enlace predeterminado es identity, lo cual es análogo a ajustar un modelo de RLM. Puede emplear también enlaces log, e inverse.\nbinomial(): Utilizada para variables dependientes binarias (0, 1). El enlace predeterminado es logit, que es el más común en la regresión logística. También admite enlaces como probit, cauchit, log, y cloglog.\npoisson(): Usada para variables dependientes numéricas discretas. El enlace predeterminado es el logaritmo (log), y también admite identity y sqrt.\nOtras familias como Gamma(), inverse.gaussian(), quasi(), quasipoisson(), y quasibinomial() para diferentes distribuciones de errores que no abordaremos en el curso.\n\nSi la función de enlace no se especifica, se utiliza el enlace canónico (predeterminado) para cada familia. Por ejemplo, si omitimos el argumento link = \"logit\", de todas maneras quedaría definido ese mismo enlace para la familia binomial.\nData: Nombre del dataframe que contiene las variables utilizadas en el modelo.\n\n\nGestión de variables dicotómicas\nDecíamos que el modelo con enlace logit es un modelo de regresión típico:\n\\[\nY = f(X + E)\n\\]\ndonde la variable respuesta (variable aleatoria \\(Y\\)) es dicotómica o binaria (toma dos valores: 0 y 1), habitualmente sobre si nuestra unidad de análisis tiene una característica (1) o no la tiene (0).\nNuestras variables dicotómicas pueden tener originalmente formatos variados y sus categorías también pueden definirse con etiquetas diferentes. Por ejemplo, podemos tener variables dicotómicas con formato lógico (+/-, TRUE/FALSE), con formato caracter (Si/No, Vivo/Muerto, etc.) o con formato numérico codificado (0-1, 1-2 o cualquier combinación personalizada de códigos).\nEn R las variables categóricas que utilizamos como dependientes en estos modelos corresponden convenientemente al tipo de datos factor. Recordemos que un factor es, interna y técnicamente, una variable numérica compuesta de enteros sucesivos a partir de 1. Cada entero es un nivel o categoría de la variable y está acompañado de una etiqueta que nos facilita recordar a qué categoría corresponde.\nLos modelos binomiales asumen las variables dicotómicas codificándolas como 0 y 1, lo cuál podría ser problemático si, como numéricos, los factores comienzan con 1. Como la estructura de los factores es conocida por las funciones que estiman modelos logit, estas funciones convierten internamente la variable categórica/factor en una variable codificada como 0/1, sin que el usuario tenga que hacer nada.\nPor lo tanto, no es necesario recodificar la variable o convertirla en dummy, esto se procesa de manera transparente para el usuario. Lo único que debemos asegurarnos es que la variable sea factor y que el nivel de referencia sea la ausencia de la característica (por ejemplo, enfermedad = No).\nDebemos usar la función levels() de R base para consultar los niveles o categorías de un factor e identificar el primer nivel del factor, que será el nivel de referencia en el modelo, es decir, \\(Y=0\\).\nPodemos modificar estos niveles de referencia mediante la función relevel() de R base o con fct_rev() de tidyverse, cuando estos se encuentren invertidos.\n\n# Factor con dos categorías\nfactor &lt;- factor(c(\"1\", \"0\", \"1\", \"1\", \"0\"))\n\n# Cambio nivel de referencia en R base\nrelevel(factor, ref = \"1\")\n\n[1] 1 0 1 1 0\nLevels: 1 0\n\n# Cambio nivel de referencia en tidyverse\nfct_rev(factor)\n\n[1] 1 0 1 1 0\nLevels: 1 0\n\n\nEste procesamiento es extensivo a las variables categóricas (dicotómica o politómicas) que se incluyen en los modelos de regresión como explicativas. En tidyverse, podemos cambiar los niveles de referencia de un factor con más de dos categorías con la función fct_relevel().\n\n# Factor con más de dos categorías\nfactor &lt;- factor(c(\"CONF\", \"DESC\", \"SOSP\", \"CONF\", \"DESC\", \"PROB\"))\n\n# Niveles por defecto\nlevels(factor)\n\n[1] \"CONF\" \"DESC\" \"PROB\" \"SOSP\"\n\n# Pongo DESC como nivel de referencia\nfct_relevel(factor, \"DESC\", after = 0)\n\n[1] CONF DESC SOSP CONF DESC PROB\nLevels: DESC CONF PROB SOSP\n\n\n\n\nAjuste del modelo\nLa razón de verosimilitud en un modelo de regresión puede calcularse restando la devianza del modelo con predictores de la del modelo nulo:\n\nmodelo$null.deviance - modelo$deviance\n\n[1] 55.60009\n\n\nEn este cálculo, estamos comparando la null deviance (modelo sin predictores) con la residual deviance (modelo con predictores). Alternativamente, la función anova() proporciona una tabla detallada que desglosa la contribución de cada variable al modelo junto con sus respectivas devianzas.\n\nanova(modelo)\n\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: y\n\nTerms added sequentially (first to last)\n\n     Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    \nNULL                   199     277.08              \nx1    2    4.080       197     273.00    0.1301    \nx2    1   51.521       196     221.48 7.085e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEn un modelo con múltiples predictores, no todas las variables necesariamente aportan información relevante. Identificar y excluir aquellas con menor impacto puede simplificar el modelo sin comprometer su capacidad predictiva. Es fundamental definir qué se entiende por “variable relevante”, ya que la importancia de una variable no debe evaluarse únicamente desde el punto de vista estadístico. El marco conceptual es clave en la selección de predictores, especialmente cuando el objetivo del modelo es analítico. La decisión debe basarse tanto en el conocimiento del área de estudio como en la evidencia estadística.\nUn error común es suponer que los métodos estadísticos pueden sustituir el conocimiento sustantivo del problema. El abuso de modelos de regresión sin una adecuada justificación teórica puede llevar a asociaciones espurias o a resultados estadísticamente significativos pero clínicamente, biológicamente o socialmente irrelevantes.\nExisten diversos métodos estadísticos para la selección de variables en regresión logística. Estos buscan lograr un modelo parsimonioso que se ajuste bien a los datos sin incluir predictores innecesarios. Si bien estos procedimientos son similares a los utilizados en regresión lineal múltiple, algunos criterios de selección específicos varían.",
    "crumbs": [
      "Regresión logística"
    ]
  },
  {
    "objectID": "unidad_1.html",
    "href": "unidad_1.html",
    "title": "Unidad 1",
    "section": "",
    "text": "Este material es parte del curso interno de Introducción a la Revisión Sistemática con Meta-análisis  © 2025 Instituto Nacional de Epidemiología “Dr. Juan H. Jara” (ANLIS) -  CC BY-NC 4.0      \n\n\n Volver arriba",
    "crumbs": [
      "Unidad 1: Revisión Sistemática"
    ]
  },
  {
    "objectID": "unidad_2.html",
    "href": "unidad_2.html",
    "title": "Unidad 2: Meta-Análisis de Efectos Fijos y Efectos Aleatorios",
    "section": "",
    "text": "Este material es parte del curso interno de Introducción a la Revisión Sistemática con Meta-análisis  © 2025 Instituto Nacional de Epidemiología “Dr. Juan H. Jara” (ANLIS) -  CC BY-NC 4.0      \n\n\n Volver arriba",
    "crumbs": [
      "Unidad 2: Meta-Análisis de Efectos Fijos y Efectos Aleatorios"
    ]
  },
  {
    "objectID": "unidad_3.html",
    "href": "unidad_3.html",
    "title": "Unidad 3",
    "section": "",
    "text": "Este material es parte del curso interno de Introducción a la Revisión Sistemática con Meta-análisis  © 2025 Instituto Nacional de Epidemiología “Dr. Juan H. Jara” (ANLIS) -  CC BY-NC 4.0      \n\n\n Volver arriba",
    "crumbs": [
      "Unidad 3: Meta-Análisis de Efectos Mixtos"
    ]
  }
]