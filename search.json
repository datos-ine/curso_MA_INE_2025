[
  {
    "objectID": "unidad_3.html",
    "href": "unidad_3.html",
    "title": "Unidad 3: Meta-Análisis de Efectos Mixtos",
    "section": "",
    "text": "Este material es parte del curso interno de Introducción a la Revisión Sistemática con Meta-análisis  © 2025 Instituto Nacional de Epidemiología “Dr. Juan H. Jara” (ANLIS) -  CC BY-NC 4.0      \n\n\n Volver arriba",
    "crumbs": [
      "Unidad 3",
      "Unidad 3: Meta-Análisis de Efectos Mixtos"
    ]
  },
  {
    "objectID": "tipos_estimador.html",
    "href": "tipos_estimador.html",
    "title": "Modelos descriptivos y analíticos",
    "section": "",
    "text": "Este material es parte del curso interno de Introducción a la Revisión Sistemática con Meta-análisis  © 2025 Instituto Nacional de Epidemiología “Dr. Juan H. Jara” (ANLIS) -  CC BY-NC 4.0",
    "crumbs": [
      "Unidad 2: Meta-análisis",
      "Modelos descriptivos y analíticos"
    ]
  },
  {
    "objectID": "tipos_estimador.html#meta-análisis-para-estudios-descriptivos",
    "href": "tipos_estimador.html#meta-análisis-para-estudios-descriptivos",
    "title": "Modelos descriptivos y analíticos",
    "section": "Meta-análisis para estudios descriptivos",
    "text": "Meta-análisis para estudios descriptivos\nPara estudios observacionales de tipo descriptivo, los estimadores de efecto más comunmente utilizados son las proporciones y las correlaciones.\n\nMeta-análisis de prevalencia\nLa prevalencia de un evento de salud se calcula como una proporción usando la fórmula:\n\\[ p = \\frac{k}{n} \\]\ndonde:\n\n\\(k\\) es el número de individuos con el evento.\n\\(n\\) es el número total de individuos.\n\nEl error estándar de la proporción se estima como:\n\\[ SE_p = \\sqrt{\\frac{p(1-p)}{n}} \\]\nDebido a que las proporciones tienen un rango de entre 0 y 1, cuando nos acercamos a alguno de estos valores se comprime el error estándar y se produce la sobreestimación de los resultados.\nUna forma común de solucionar el problema es aplicar la transformación logit a las proporciones crudas. La función escalc() del paquete metafor nos permite transformar las proporciones a logit usando los siguientes argumentos:\n{r} #| eval: false  prev &lt;- escalc(measure = \"PLO\", # transformación logit de proporciones                xi = evento, # individuos con el evento                 ni = n, # total de individuos en la muestra                slab = titulo, # identificador del estudio                data = datos) # base de datos de interés}\nVeamos un ejemplo práctico usando la base de datos “dat.crisafulli2020” incluida en el paquete metadat. Comenzamos cargando la base de datos y haciendo una exploración rápida:\n{r} # Carga datos datos &lt;- dat.crisafulli2020  # Exploración datos glimpse(datos)}\nNuestras columnas de interés son study, cases y total, que contienen el identificador de estudio, el número de individuos con el evento y el número total de individuos muestreados en cada estudio. Aplicamos la transformación logit:\n{r} # Crea nuevo dataset con los datos transformados prev &lt;- escalc(measure = \"PLO\", # transformación logit de proporciones                xi = cases,                 ni = total,                slab = study,                data = datos)  # Explora objeto glimpse(prev)}\nEn el objeto que creamos con escalc(), aparecen dos nuevas columnas: yi y vi que corresponden al estimador de efecto y su varianza, respectivamente. Una vez aplicada la transformación, podemos correr el modelo de meta-análisis usando la función rma() de metafor:\n{r} mod_prev &lt;- rma(yi = yi,                  vi = vi,                  measure = \"PLO\",                 slab = study,                  data = prev)}\nUna forma más sencilla de llegar al mismo resultado, es usando la función metaprop() del paquete meta, donde en un solo paso podemos transformar los datos y ajustar el modelo de meta-análisis usando los siguientes argumentos:\n{r} mod_prev2 &lt;- metaprop(event = cases, # individuos con el evento                         n = total, # total de individuos en la muestra                          sm = \"PLOGIT\", # transformación logit                      studlab = study, # identificador del estudio                           data = prev) # base de datos de interés}\nComparemos la salida de ambos modelos:\n{r} summary(mod_prev)  summary(mod_prev2)}\n\n\nMeta-análisis de incidencia\n\n\nMeta-análisis de correlaciones\nLas correlaciones indican la fuerza y dirección de la covarianza entre dos variables numéricas continuas y se expresa como:\n\\[ r_{xy} = \\frac{Cov_{xy}}{S_xS_y} \\]\ndonde:\n\n\\(Cov_{xy}\\) es la covarianza entre las variables X e Y.\n\\(S_x\\) y \\(S_y\\) son los desvíos estándar para cada variable.\n\nEl error estándar para la correlación se puede expresar como:\n\\[ SE = \\frac{1 - r^2_{xy}}{\\sqrt{n-2}} \\]\nLas correlaciones pueden tomar valores de entre -1 y 1, por lo que se pueden introducir sesgos cuando calculamos el error estándar para muestras pequeñas. Para trabajar con meta-análisis de correlaciones, los datos se transforman usando el coeficiente z de Fisher, que aproxima la muestra a una distribución normal.\nEn el paquete metafor podemos realizar la transformación de los datos usando la función escalc() con los siguientes argumentos:\n{r} #| eval: false  cor &lt;- escalc(measure = \"ZCOR\", # transformación de Fisher               ri = correlacion, # vector de correlaciones                ni = n, # total de individuos en la muestra                 slab = titulo, # identificador del estudio                 data = datos) # base de datos de interés}\nLa función metacor() del paquete meta, nos permite ajustar modelos de meta-análisis para proporciones simples sin necesidad de transformar previamente los datos usando el argumento sm = \"ZCOR\":\n{r} #| eval: false  mod_cor &lt;- metacor(cor = correlacion, # vector de correlaciones                     n = n, # total de individuos en la muestra                       sm = \"ZCOR\", # transformación de Fisher                    studlab = titulo, # identificador del estudio                      data = datos) # base de datos de interés}",
    "crumbs": [
      "Unidad 2: Meta-análisis",
      "Modelos descriptivos y analíticos"
    ]
  },
  {
    "objectID": "tipos_estimador.html#meta-análisis-de-estudios-analíticos",
    "href": "tipos_estimador.html#meta-análisis-de-estudios-analíticos",
    "title": "Modelos descriptivos y analíticos",
    "section": "Meta-análisis de estudios analíticos",
    "text": "Meta-análisis de estudios analíticos\nCuando trabajamos con datos de estudios epidemiológicos analíticos, podemos realizar meta-análisis para distintas medidas de asociación.\n\nDiferencia de medias\nLa diferencia de medias entre dos o más grupos se define como:\n\\[ MD = \\bar{x_1} - \\bar{x_2} \\]\ndonde:\n\n\\(\\bar{x_1}\\) es la media muestral del grupo 1.\n\\(\\bar{x_2}\\) es la media muestral del grupo 2.\n\nEl error estándar para la diferencia de medias se obtiene como:\n\\[ SE_{md} = S_{comb} \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}} \\]\ndonde \\(n_1\\) y \\(n_2\\) son los tamaños muestrales en ambos grupos y \\(S_{comb}\\) es el desvío estándar combinado.\nLa función metacont() del paquete meta, nos permite ajustar modelos de meta-análisis para diferencia de medias:\n{r} #| eval: false  mod_mean &lt;- metacont(n.e = expuestos, # individuos expuestos                      mean.e = media_exp, # media en expuestos                      sd.e = sd_exp, # desvío estándar en expuestos                      n.c = no_exp, # individuos no expuestos                      mean.c = media_no_exp, # media en no expuestos                      sd.c = sd_no_exp, # desvío estándar en no expuestos                      studlab = titulo, # identificador del estudio                      data = datos) # base de datos de interés}\n\n\nOdds-ratio\nLa función metabin() del paquete meta, nos permite ajustar modelos de meta-análisis para el odds-ratio:\n{r} #| eval: false  mod_or &lt;- metabin(event.e = eventos_exp, # eventos en expuestos                   n.e = n_exp, # individuos expuestos                   event.c = eventos_no_exp, # eventos en no expuestos                    n.c = n_no_exp, # individuos no expuestos                     sm = \"OR\", # Odds-ratio                    studlab = titulo, # identificador del estudio                      data = datos) # base de datos de interés}\n\n\nRiesgo relativo\nLa función metabin() del paquete meta, nos permite ajustar modelos de meta-análisis para el riesgo relativo:\n{r} #| eval: false  mod_rr &lt;- metabin(event.e = eventos_exp, # eventos en expuestos                   n.e = n_exp, # individuos expuestos                   event.c = eventos_no_exp, # eventos en no expuestos                    n.c = n_no_exp, # individuos no expuestos                     sm = \"RR\", # Riesgo relativo                    studlab = titulo, # identificador del estudio                      data = datos) # base de datos de interés}\n\n\nTasa de incidencia\nLa función metainc() del paquete meta, nos permite ajustar modelos de meta-análisis para la tasa de incidencia:\n{r} #| eval: false  mod_IRR &lt;- metainc(event.e = eventos_exp, # eventos en expuestos                   time.e = tiempo_exp, # tiempo-persona expuestos                   event.c = eventos_no_exp, # eventos en no expuestos                    time.c = tiempo_no_exp, # tiempo-persona no expuestos                    studlab = titulo, # identificador del estudio                      data = datos) # base de datos de interés}\n\n\nTiempo hasta el evento",
    "crumbs": [
      "Unidad 2: Meta-análisis",
      "Modelos descriptivos y analíticos"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Este material es parte del curso interno de Introducción a la Revisión Sistemática con Meta-análisis  © 2025 Instituto Nacional de Epidemiología “Dr. Juan H. Jara” (ANLIS) -  CC BY-NC 4.0",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "index.html#introducción",
    "href": "index.html#introducción",
    "title": "",
    "section": "Introducción",
    "text": "Introducción",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "analisis_moderadores.html",
    "href": "analisis_moderadores.html",
    "title": "Análisis de moderadores",
    "section": "",
    "text": "Este material es parte del curso interno de Introducción a la Revisión Sistemática con Meta-análisis  © 2025 Instituto Nacional de Epidemiología “Dr. Juan H. Jara” (ANLIS) -  CC BY-NC 4.0      \n\n\n Volver arriba",
    "crumbs": [
      "Unidad 2: Meta-análisis",
      "Análisis de moderadores"
    ]
  },
  {
    "objectID": "fixed_random.html",
    "href": "fixed_random.html",
    "title": "Modelos de efectos fijos y aleatorios",
    "section": "",
    "text": "Este material es parte del curso interno de Introducción a la Revisión Sistemática con Meta-análisis  © 2025 Instituto Nacional de Epidemiología “Dr. Juan H. Jara” (ANLIS) -  CC BY-NC 4.0",
    "crumbs": [
      "Unidad 2: Meta-análisis",
      "Modelos de efectos fijos y aleatorios"
    ]
  },
  {
    "objectID": "fixed_random.html#introducción",
    "href": "fixed_random.html#introducción",
    "title": "Modelos de efectos fijos y aleatorios",
    "section": "Introducción",
    "text": "Introducción\nUno de los objetivos principales del modelado estadístico es representar la realidad de manera “sencilla”, capturando su estructura esencial y descartando elementos cuya variabilidad podría generar ruido en la interpretación de los fenómenos.\nPara ajustar un modelo estadístico, partimos de los datos disponibles y buscamos construir una representación de la realidad basada en ellos. En el caso de los modelos de meta-análisis, los datos de interés son los estimadores de efecto obtenidos en cada estudio, y el objetivo es entender las causas de la variabilidad entre esos estimadores.\nDe esta manera, se distinguen dos enfoques principales en meta-análisis: los modelos de efectos fijos y los modelos de efectos aleatorios. Dado el alcance de este curso, no profundizaremos en los detalles matemáticos de estos modelos, sino que nos centraremos en sus principales características y en su implementación en R. Quienes tengan interés en profundizar más en estos enfoques pueden consultar los libros de meta-análisis en R de Schwarzer, Carpenter, y Rücker (2015) y Harrer et al. (2021).",
    "crumbs": [
      "Unidad 2: Meta-análisis",
      "Modelos de efectos fijos y aleatorios"
    ]
  },
  {
    "objectID": "fixed_random.html#modelos-de-efectos-fijos",
    "href": "fixed_random.html#modelos-de-efectos-fijos",
    "title": "Modelos de efectos fijos y aleatorios",
    "section": "Modelos de efectos fijos",
    "text": "Modelos de efectos fijos\nEl modelo de efectos fijos parte de la premisa de que todos los estimadores de efecto incluidos en el meta-análisis provienen de una misma población homogénea, y que las diferencias observadas entre ellos se deben exclusivamente al error muestral. En este enfoque, se supone que existe un único “verdadero” efecto común que subyace a todos los estudios, por lo que el objetivo principal es estimar este valor a partir de los datos disponibles.\nEl estimador de efecto global corresponde entonces a un promedio ponderado de los estimadores individuales, donde los pesos asignados dependen del tamaño de la muestra y la precisión de cada estudio. De este modo, los estudios con menor varianza tienen mayor influencia en la estimación final.\nDado que el modelo de efectos fijos asume la homogeneidad entre los estudios, no considera la posibilidad de que existan fuentes adicionales de variabilidad más allá del error aleatorio. Por esta razón, también se le conoce como modelo de efectos comunes (common effects model) o de efectos equivalentes (equal effects model). Sin embargo, en la práctica, es común encontrar heterogeneidad entre los estudios, lo que hace que los modelos de efectos fijos sean, en muchos casos, inadecuados.",
    "crumbs": [
      "Unidad 2: Meta-análisis",
      "Modelos de efectos fijos y aleatorios"
    ]
  },
  {
    "objectID": "fixed_random.html#modelos-de-efectos-aleatorios",
    "href": "fixed_random.html#modelos-de-efectos-aleatorios",
    "title": "Modelos de efectos fijos y aleatorios",
    "section": "Modelos de efectos aleatorios",
    "text": "Modelos de efectos aleatorios\nLos modelos de efectos aleatorios suponen que existe una fuente de variabilidad entre los estudios que va más allá del error aleatorio. Esta fuente adicional de variabilidad implica que los estudios no provienen de una única población, sino de un conjunto de posibles poblaciones.\nEn este enfoque, el estimador del efecto real no es único, sino que se distribuye alrededor de una media general. Esto introduce una segunda fuente de error que debe ser incorporada en el modelo. El objetivo de los modelos de efectos aleatorios es, por lo tanto, estimar la media de la distribución de los efectos, considerando tanto la variabilidad dentro de cada estudio como la variabilidad entre estudios.\n\nHeterogeneidad estadística\nEn un meta-análisis existen tres fuentes potenciales de variabilidad: heterogeneidad de base (entre participantes de cada estudio), heterogeneidad estadística y heterogeneidad por otras causas (por ejemplo, el error de muestreo).\nLa heterogeneidad estadística refleja la variabilidad existente entre los estudios incluidos en un meta-análisis. A continuación, se presenta una comparación entre los principales indicadores:\n\n\n\nIndicador\nDescripción\nEscala\nNúmero de estudios\nPrecisión\n\n\n\n\nQ de Cochran\nEvalúa si las diferencias entre los estimadores de efecto son mayores a las esperadas por azar\nAbsoluta\nDependiente\nDependiente\n\n\nI-cuadrado (I²)\nRepresenta el porcentaje de variabilidad total atribuible a la heterogeneidad entre estudios\nPorcentaje\nIndependiente\nDependiente\n\n\ntau-cuadrado (τ²)\nEstima la varianza real entre los efectos de los estudios.\nEfecto\nIndependiente\nIndependiente\n\n\nH²\nRefleja la magnitud de la heterogeneidad en los estudios.\nAbsoluta\nIndependiente\nDependiente\n\n\nR²\nMide la proporción de la varianza total explicada por el modelo en relación con la variabilidad total de los efectos.\nAbsoluta\nIndependiente\nDependiente\n\n\n\nEstos indicadores permiten evaluar si las diferencias entre los efectos observados son mayores de lo que se esperaría por azar, lo que ayuda a determinar el modelo de meta-análisis más adecuado.",
    "crumbs": [
      "Unidad 2: Meta-análisis",
      "Modelos de efectos fijos y aleatorios"
    ]
  },
  {
    "objectID": "fixed_random.html#implementación-en-r",
    "href": "fixed_random.html#implementación-en-r",
    "title": "Modelos de efectos fijos y aleatorios",
    "section": "Implementación en R",
    "text": "Implementación en R\nPara ajustar modelos de meta-análisis en R, los dos paquetes más utilizados son metafor (Viechtbauer 2010) y meta (Balduzzi, Rücker, y Schwarzer 2019).\n\nmetafor: Es un paquete muy flexible y potente que permite modelar escenarios complejos con alta precisión. Sin embargo, su uso requiere una curva de aprendizaje más pronunciada y un conocimiento avanzado en modelado estadístico.\nmeta: Es más accesible y fácil de usar, lo que lo convierte en una excelente opción para quienes tienen solo posean conocimientos básicos de estadística inferencial. Este paquete es ideal para aplicaciones prácticas y proporciona una interfaz más simple y directa para realizar análisis estándar.\n\nDado que este curso se enfoca en la aplicación práctica del meta-análisis, utilizaremos principalmente el paquete meta, que ajusta de manera predeterminada tanto modelos de efectos fijos como de efectos aleatorios para cada conjunto de datos, e incluye distintos estimadores de heterogeneidad estadística.\n\nEjemplo práctico\nLa función principal del paquete meta para realizar un meta-análisis es metaxx(), donde xx representa el tipo de estimador de efecto que vamos a calcular (por ejemplo, metacont para diferencias de medias, metaprop para proporciones, etc.). A continuación presentamos la estructura básica de esta función:\n\nmetaxx(studlab, # Identificador de estudio\n       data,    # Base de datos de interés\n       sm,      # Estimador de efecto global\n       common = TRUE, # Modelo de efectos fijos\n       random = TRUE, # Modelo de efectos aleatorios \n       backtransf = TRUE, # Escala de los resultados\n       subset,        # Opcional, para filtrar estudios\n       exclude,       # Opcional, para excluir estudios\n       subgroup,      # Opcional, para análisis de subgrupos\n       cluster        # Opcional, para modelos multinivel\n)\n\nDonde:\n\nstudlab: Identificador, nombre o código único de cada estudio en el conjunto de datos.\ndata: El conjunto de datos que contiene los resultados de los estudios a incluir en el meta-análisis.\nsm: Especifica el estimador de efecto global a calcular. Algunos ejemplos comunes son: “OR” (odds-ratio), “RR” (riesgo relativo) y “MD” (diferencia de medias).\ncommon: Establece si se utilizará el modelo de efectos fijos. La opción por defecto es TRUE, pero podemos especificar FALSE si no deseamos obtener los resultados de este modelo.\nrandom: Establece si se ajustará un modelo de efectos aleatorios. La opción por defecto es TRUE, pero podemos especificar FALSE si no deseamos obtener los resultados de este modelo.\nbacktransf: Define si los resultados deben mostrarse en la escala original (TRUE, por ejemplo, convertir log-OR a odds-ratio) o transformados (FALSE).\nsubset: Permite filtrar un subconjunto de estudios para el análisis (opcional).\nexclude: Permite excluir ciertos estudios del análisis (opcional).\nsubgroup: Permite realizar un análisis por subgrupos (opcional).\ncluster: Permite ajustar modelos multinivel si los datos están agrupados en clústeres (opcional).\n\nPara desarrollar el ejemplo comenzaremos cargando el paquete meta y la base de datos dat.cohen1981, que contiene los resultados de 20 estudios que analizan la correlación entre las calificaciones de los instructores de un curso y el rendimiento académico de los estudiantes. Este conjunto de datos está disponible en la dependencia metadat:\n\n# Cargar el paquete meta\nlibrary(meta)\n\nLoading required package: metadat\n\n\nLoading 'meta' package (version 8.0-2).\nType 'help(meta)' for a brief overview.\n\n# Cargar datos\ndata(\"dat.cohen1981\")\n\nAjustamos el modelo usando la función metacor(), las variables de entrada serán ri (correlaciones) y ni (tamaño muestral de cada estudio):\n\n# Ajustar el modelo de efectos fijos y aleatorios\nmod &lt;- metacor(cor = ri,  # Variable que contiene los datos de correlación\n               n = ni,    # Variable que contiene el tamaño muestral\n               studlab = study,\n               common = TRUE,    \n               random = TRUE,    \n               backtransf = TRUE, \n               data = dat.cohen1981)\n\n# Salida del modelo\nsummary(mod)\n\n                           COR            95%-CI %W(common) %W(random)\nBolton et al. 1979      0.6800 [ 0.0881; 0.9170]        1.3        1.6\nBryson 1974             0.5600 [ 0.1562; 0.8034]        3.2        3.6\nCentra 1977             0.2300 [-0.3676; 0.6931]        1.9        2.2\nCentra 1977             0.6400 [ 0.2991; 0.8360]        3.6        4.0\nCrooks & Smock 1974     0.4900 [ 0.1431; 0.7297]        4.7        5.2\nDoyle & Crichton 1978  -0.0400 [-0.6001; 0.5464]        1.7        2.0\nDoyle & Whitely 1974    0.4900 [-0.1167; 0.8304]        1.7        2.0\nElliott 1950            0.3300 [ 0.0016; 0.5941]        6.2        6.6\nEllis & Rickard 1977    0.5800 [ 0.1708; 0.8186]        3.0        3.5\nFrey et al. 1975        0.1800 [-0.4393; 0.6833]        1.7        2.0\nGreenwood et al. 1976  -0.1100 [-0.4232; 0.2267]        6.2        6.6\nHoffman 1978            0.2700 [ 0.0458; 0.4683]       13.6       12.2\nMcKeachie et al. 1971   0.2600 [-0.0915; 0.5539]        5.7        6.1\nMorsh et al. 1956       0.4000 [ 0.2385; 0.5399]       22.3       17.1\nRemmers et al. 1949     0.4900 [ 0.1973; 0.7025]        6.4        6.7\nSullivan & Skanes 1974  0.5100 [-0.0282; 0.8190]        2.1        2.4\nSullivan & Skanes 1974  0.4000 [ 0.1011; 0.6327]        7.0        7.2\nSullivan & Skanes 1974  0.3400 [-0.1873; 0.7152]        2.5        2.8\nSullivan & Skanes 1974  0.4200 [-0.1423; 0.7774]        2.1        2.4\nWherry 1952             0.1600 [-0.3040; 0.5627]        3.2        3.6\n\nNumber of studies: k = 20\nNumber of observations: o = 590\n\n                        COR           95%-CI    z  p-value\nCommon effect model  0.3626 [0.2865; 0.4342] 8.75 &lt; 0.0001\nRandom effects model 0.3637 [0.2788; 0.4430] 7.88 &lt; 0.0001\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0052 [0.0000; 0.0632]; tau = 0.0723 [0.0000; 0.2514]\n I^2 = 9.4% [0.0%; 44.6%]; H = 1.05 [1.00; 1.34]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 20.97   19  0.3382\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Fisher's z transformation of correlations\n\n\nSi solo nos interesa calcular el modelo de efectos aleatorios (sin efectos fijos), simplemente ajustamos el parámetro common = FALSE:\n\n# Ajustar solo el modelo de efectos aleatorios\nmod &lt;- metacor(cor = ri,  # Variable que contiene los datos de correlación\n               n = ni,    # Variable que contiene el tamaño muestral\n               studlab = study,  \n               common = FALSE,   # Desactivar modelo de efectos fijos\n               random = TRUE,\n               backtransf = TRUE, \n               data = dat.cohen1981)\n\n# Salida del modelo\nsummary(mod)\n\n                           COR            95%-CI %W(random)\nBolton et al. 1979      0.6800 [ 0.0881; 0.9170]        1.6\nBryson 1974             0.5600 [ 0.1562; 0.8034]        3.6\nCentra 1977             0.2300 [-0.3676; 0.6931]        2.2\nCentra 1977             0.6400 [ 0.2991; 0.8360]        4.0\nCrooks & Smock 1974     0.4900 [ 0.1431; 0.7297]        5.2\nDoyle & Crichton 1978  -0.0400 [-0.6001; 0.5464]        2.0\nDoyle & Whitely 1974    0.4900 [-0.1167; 0.8304]        2.0\nElliott 1950            0.3300 [ 0.0016; 0.5941]        6.6\nEllis & Rickard 1977    0.5800 [ 0.1708; 0.8186]        3.5\nFrey et al. 1975        0.1800 [-0.4393; 0.6833]        2.0\nGreenwood et al. 1976  -0.1100 [-0.4232; 0.2267]        6.6\nHoffman 1978            0.2700 [ 0.0458; 0.4683]       12.2\nMcKeachie et al. 1971   0.2600 [-0.0915; 0.5539]        6.1\nMorsh et al. 1956       0.4000 [ 0.2385; 0.5399]       17.1\nRemmers et al. 1949     0.4900 [ 0.1973; 0.7025]        6.7\nSullivan & Skanes 1974  0.5100 [-0.0282; 0.8190]        2.4\nSullivan & Skanes 1974  0.4000 [ 0.1011; 0.6327]        7.2\nSullivan & Skanes 1974  0.3400 [-0.1873; 0.7152]        2.8\nSullivan & Skanes 1974  0.4200 [-0.1423; 0.7774]        2.4\nWherry 1952             0.1600 [-0.3040; 0.5627]        3.6\n\nNumber of studies: k = 20\nNumber of observations: o = 590\n\n                        COR           95%-CI    z  p-value\nRandom effects model 0.3637 [0.2788; 0.4430] 7.88 &lt; 0.0001\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0052 [0.0000; 0.0632]; tau = 0.0723 [0.0000; 0.2514]\n I^2 = 9.4% [0.0%; 44.6%]; H = 1.05 [1.00; 1.34]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 20.97   19  0.3382\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Fisher's z transformation of correlations\n\n\nAl ejecutar summary(mod), la primera sección de la salida muestra los resultados individuales de cada estudio incluido en el meta-análisis. Para cada uno, se presentan:\n\nCOR: coeficiente de correlación, que representa la asociación entre las calificaciones del instructor y el rendimiento estudiantil.\n95%-CI: intervalo de confianza al 95% para el coeficiente de correlación.\n%W (random): peso asignado a cada estudio en el modelo de efectos aleatorios, determinado por el tamaño de la muestra y la varianza de cada estimación.\n\nLuego se muestran los resultados generales del meta-análisis:\n\nk: número total de estudios incluidos.\no: número total de observaciones.\nCOR 95%-CI: coeficiente de correlación global con su intervalo de confianza al 95%.\nEl estadístico z y susignificancia (p-value)\n\nA continuación, se presentan las métricas de heterogeneidad:\n\ntau^2 y tau: cuantifican la variabilidad entre estudios más allá del error muestral.\nI^2: indica la proporción de variabilidad observada que se debe a diferencias reales entre los estudios.\nH y Q: estadísticos que evalúan si existe variabilidad sustancial entre los estudios.\n\nFinalmente, la salida del modelo detalla los métodos estadísticos utilizados, incluyendo el método de varianza inversa para ponderar los estudios, el estimador de máxima verosimilitud restringida para \\(\\tau^2\\) y la transformación de Fisher para estabilizar la varianza.\n\nInterpretación\nEl meta-análisis realizado sobre 20 estudios individuales, muestra una correlación positiva estadísticamente significativa (\\(p &lt; 0.0001\\)) entre las calificaciones del instructor y el rendimiento estudiantil, con una baja heterogeneidad estadística entre estudios (\\(I^2 = 9,4\\%\\)).\n\n\nForest plots\nSon representaciones gráficas de los resultados del modelo de meta-análisis, que muestran los estimadores para cada estudio junto al estimador global y los índices de heterogeneidad estadística correspondientes.\nSe pueden generar forest plot rápidos usando la función forest():\n\nforest(mod)\n\n\n\n\n\n\n\n\nSi bien esta función permite algunas opciones de configuración para los gráficos, existen otros paquetes de R que permiten generar forest plots visualmente más atractivos.\nEn la segunda parte de esta unidad, exploraremos las funciones específicas de meta utilizadas para calcular diferentes estimadores de efecto epidemiológico, así como los argumentos principales que permite ajustar. Además, abordaremos métodos para controlar la heterogeneidad observada, tales como el análisis de subgrupos (también conocido como análisis de moderadores) y la meta-regresión.",
    "crumbs": [
      "Unidad 2: Meta-análisis",
      "Modelos de efectos fijos y aleatorios"
    ]
  },
  {
    "objectID": "fixed_random.html#sesgo-de-publicación",
    "href": "fixed_random.html#sesgo-de-publicación",
    "title": "Modelos de efectos fijos y aleatorios",
    "section": "Sesgo de publicación",
    "text": "Sesgo de publicación\nEl sesgo de publicación (publication bias) ocurre cuando los resultados de los estudios publicados no son representativos de todos los estudios realizados sobre un tema. Esto puede distorsionar la síntesis de la evidencia en un meta-análisis, ya que los estudios con resultados positivos o significativos tienen más probabilidades de ser publicados que aquellos con resultados nulos o negativos, comprometiendo la validez de las conclusiones del meta-análisis.\nEste sesgo puede influir considerablemente en los resultados de un meta-análisis, ya que si los estudios publicados no reflejan adecuadamente toda la gama de resultados posibles, la estimación del efecto global puede estar sesgada. Por lo tanto, es esencial evaluar y ajustar el sesgo de publicación al realizar un meta-análisis, a fin de garantizar que los resultados sean lo más precisos y representativos posible.\nFunnel plot\nEs una herramienta gráfica que permite observar la relación entre el estimador de efecto y su variabilidad. En ausencia de sesgo de publicación, se espera que los estudios se distribuyan simétricamente alrededor del estimador de efecto global, formando un patrón similar a un embudo. Si existe sesgo de publicación, los estudios con mayor tamaño de muestra (y, por tanto, mayor precisión) estarán más concentrados en el centro, mientras que los estudios con menor tamaño de muestra se dispersarán de manera asimétrica.\nLa función funnel() del paquete meta permite generar este diagrama para una visualización rápida.\n\nfunnel(mod)\n\n\n\n\n\n\n\n\nTest de Egger\nEvalúa la simetría del funnel plot mediante una regresión lineal entre el estimador de efecto y su error estándar. En presencia de sesgo de publicación, se espera que los puntos del diagrama no estén distribuidos simétricamente. Este test proporciona una estimación estadística del sesgo de publicación: un p-valor menor que 0,05 sugiere la presencia de sesgo de publicación.\nEste test puede implementarse con la función metabias():\n\nmetabias(mod)\n\nLinear regression test of funnel plot asymmetry\n\nTest result: t = 0.49, df = 18, p-value = 0.6323\nBias estimate: 0.3007 (SE = 0.6177)\n\nDetails:\n- multiplicative residual heterogeneity variance (tau^2 = 1.1501)\n- predictor: standard error\n- weight:    inverse variance\n- reference: Egger et al. (1997), BMJ\n\n\nTest de Begg\nEvalúa la relación entre el tamaño del efecto y el error estándar, utilizando un enfoque basado en la correlación de rangos en lugar de una regresión lineal. Un p-valor menor que 0,05 indica la presencia de sesgo de publicación.\nEste test puede implementarse con la función metabias(), utilizando el argumento method.bias = \"Begg\":\n\nmetabias(mod, method.bias = \"Begg\")\n\nRank correlation test of funnel plot asymmetry\n\nTest result: z = 0.26, p-value = 0.7945\nBias estimate: 8.0000 (SE = 30.7137)\n\nReference: Begg & Mazumdar (1993), Biometrics\n\n\nTrim-and-fill\nEstima el número de estudios faltantes debido al sesgo de publicación y ajusta la media global en consecuencia, agregando estudios hipotéticos que representarían los estudios no publicados. Este método ayuda a corregir la estimación del efecto global al incluir los estudios faltantes que no se publicaron debido a su falta de significancia.\nEn R, este procedimiento puede implementarse con la función trimfill():\n\ntrimfill(mod)\n\nNumber of studies: k = 22 (with 2 added studies)\n\n                        COR           95%-CI    z  p-value\nRandom effects model 0.3430 [0.2541; 0.4261] 7.17 &lt; 0.0001\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0092 [0.0000; 0.0783]; tau = 0.0957 [0.0000; 0.2799]\n I^2 = 18.5% [0.0%; 51.4%]; H = 1.11 [1.00; 1.43]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 25.76   21  0.2156\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Trim-and-fill method to adjust for funnel plot asymmetry (L-estimator)\n- Fisher's z transformation of correlations\n\n\nGeneralmente, se recomienda utilizar dos o más estimadores de sesgo de publicación para obtener una visión más completa de la posible presencia de este sesgo. Utilizando diferentes métodos, es posible realizar una evaluación más robusta y precisa del sesgo de publicación y su impacto en los resultados del meta-análisis.",
    "crumbs": [
      "Unidad 2: Meta-análisis",
      "Modelos de efectos fijos y aleatorios"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introducción",
    "section": "",
    "text": "Este material es parte del curso interno de Introducción a la Revisión Sistemática con Meta-análisis  © 2025 Instituto Nacional de Epidemiología “Dr. Juan H. Jara” (ANLIS) -  CC BY-NC 4.0",
    "crumbs": [
      "Unidad 2: Meta-análisis",
      "Introducción"
    ]
  },
  {
    "objectID": "intro.html#qué-es-un-meta-análisis",
    "href": "intro.html#qué-es-un-meta-análisis",
    "title": "Introducción",
    "section": "¿Qué es un meta-análisis?",
    "text": "¿Qué es un meta-análisis?\nUn meta-análisis es una herramienta estadística que permite sintetizar cuantitativamente la evidencia de investigaciones independientes sobre un mismo problema de investigación. Se lo ha definido como un “análisis de análisis”(Glass 1976), ya que su unidad de análisis no son individuos o poblaciones, sino estudios previamente realizados.\nEl objetivo principal de un meta-análisis es proporcionar un estimador numérico que resuma los resultados de los estudios incluidos, permitiendo evaluar la magnitud del efecto de una intervención o la relación entre variables en diferentes contextos (Harrer et al. 2021). Es importante destacar que los meta-análisis son adecuados únicamente para investigaciones cuantitativas y, en general, requieren que los estudios analizados compartan el mismo diseño y estimen medidas de asociación similares.\nA continuación, se presentan algunas de las principales ventajas y limitaciones del meta-análisis:\n\n\n\nVentajas\nDesventajas\n\n\n\n\nPermite una síntesis cuantitativa de la evidencia disponible.\nLa validez de los resultados depende de la calidad metodológica de los estudios incluidos.\n\n\nAumenta la potencia estadística al combinar los datos de múltiples estudios.\nPuede estar afectado por sesgos de publicación.\n\n\nMejora la precisión de los estimadores al reducir la variabilidad aleatoria.\nLa heterogeneidad entre estudios puede dificultar la interpretación de los resultados.\n\n\nPermite identificar patrones no evidentes en estudios individuales.\nRequiere una metodología rigurosa y criterios estrictos de selección de estudios.\n\n\nEvalúa la consistencia de los resultados en diferentes poblaciones y contextos.\nNo corrige errores metodológicos de los estudios primarios.",
    "crumbs": [
      "Unidad 2: Meta-análisis",
      "Introducción"
    ]
  },
  {
    "objectID": "intro.html#estimadores-de-efecto",
    "href": "intro.html#estimadores-de-efecto",
    "title": "Introducción",
    "section": "Estimadores de efecto",
    "text": "Estimadores de efecto\nEn estudios individuales, se asume que las variables de interés fueron medidas de manera uniforme en todos los participantes. Esto permite aplicar técnicas de estadística descriptiva, como el análisis exploratorio de datos (EDA), para caracterizar la muestra y evaluar relaciones entre variables.\nSin embargo, en los meta-análisis esta suposición no siempre se cumple. Aunque los criterios de inclusión sean estrictos, los estudios pueden diferir en diseño, población, medición de variables o definición de resultados. Por ello, no es posible sintetizar la evidencia utilizando exclusivamente herramientas de la estadística tradicional.\nPara integrar los resultados de diferentes estudios, los meta-análisis utilizan estimadores de efecto (effect size). En algunos casos, estos valores se extraen directamente de los artículos, pero a menudo deben calcularse a partir de los datos reportados. Un buen estimador de efecto debe cumplir con las siguientes condiciones:\n\nComparable: Debe ser consistente entre los estudios incluidos.\nComputable: Debe poder calcularse a partir de la información disponible.\nConfiable: Debe permitir estimar su error estándar.\nInterpretable: Debe responder adecuadamente a la pregunta de investigación.\n\nDesde una perspectiva estadística, los estimadores de efecto son equivalentes a los coeficientes en modelos de regresión o a las medidas de asociación en estudios epidemiológicos, ya que cuantifican la fuerza y dirección de la relación entre dos variables. Algunos estimadores de efecto comúnmente utilizados en investigación epidemiológica y aplicables a modelos de meta-análisis incluyen: proporción, incidencia, correlación, diferencia de medias, odds-ratio (OR), riesgo relativo (RR) y hazard-ratio.\nEn las próximas secciones, exploraremos los modelos de meta-análisis de efectos fijos y/o aleatorios más adecuados para cada estimador de efecto y su implementación en software R,",
    "crumbs": [
      "Unidad 2: Meta-análisis",
      "Introducción"
    ]
  },
  {
    "objectID": "unidad_1.html",
    "href": "unidad_1.html",
    "title": "Unidad 1: Revisión Sistemática",
    "section": "",
    "text": "Este material es parte del curso interno de Introducción a la Revisión Sistemática con Meta-análisis  © 2025 Instituto Nacional de Epidemiología “Dr. Juan H. Jara” (ANLIS) -  CC BY-NC 4.0      \n\n\n Volver arriba",
    "crumbs": [
      "Unidad 1",
      "Unidad 1: Revisión Sistemática"
    ]
  }
]